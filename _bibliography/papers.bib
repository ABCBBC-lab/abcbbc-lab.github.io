@article{bauerExploringMarineMammal2026,
  title = {Exploring Marine Mammal Cognition as a Conservation Tool},
  author = {Bauer, Gordon B. and Cook, Peter F. and Harley, Heidi E. and Bruck, Jason and Cosentino, Mel and Deutsch, Charles J. and Erdsack, Nicola and Fellner, Wendi and Gunnars, Tabitha and Manitzas Hill, Heather and Kumar, Sonia V. and Lilley, Malin K. and McHugh, Katherine A. and Moore, Jennifer and Moron, Juliana R. and Ravignani, Andrea and Reep, Roger L. and Rycyk, Athena M. and Sayigh, Laela S. and Szegedi, Anik{\'o} and Toms, Christina and Wells, Randall S.},
  year = 2026,
  month = jan,
  journal = {Marine Mammal Science},
  volume = {42},
  number = {1},
  pages = {e70114},
  issn = {0824-0469, 1748-7692},
  doi = {10.1111/mms.70114},
  urldate = {2026-02-26},
  abstract = {ABSTRACT             Cognition is an animal's real-time adaptation system for responding to change. Rapid environmental change, often anthropogenic, is expanding the range and severity of challenges confronting wild animals. Effective conservation requires a multifaceted approach that includes animals' capacities. Large-brained, long-lived animals such as marine mammals often have extensive capability to adaptively modify their behavior due to their cognition, which comprises the mechanisms of information acquisition, processing, and flexible action. Consequently, current behavior need not be a final predictor of future behavior for these animals. This flexibility provides an underutilized and under examined point of leverage for humans interested in improving life outcomes for wild animals. In this team-written, interdisciplinary paper, we argue that application of cognitive approaches may facilitate many conservation efforts directed toward marine mammals. Starting with a workshop on this topic at the 24th Biennial Conference on the Biology of Marine Mammals, scientists representing a wide range of disciplinary expertise addressed eight different conservation concerns for six marine mammal species and provided potential cognitive explanations of and interventions aimed at related behavior. Our treatment highlights the value of integrated laboratory and field research, and the importance of tight lines of communication between scientists and conservation managers.},
  langid = {english}
}

@article{biancoNeuralEncodingMusical2024,
  title = {Neural Encoding of Musical Expectations in a Non-Human Primate},
  author = {Bianco, Roberta and Zuk, Nathaniel J. and Bigand, F{\'e}lix and Quarta, Eros and Grasso, Stefano and Arnese, Flavia and Ravignani, Andrea and {Battaglia-Mayer}, Alexandra and Novembre, Giacomo},
  year = 2024,
  month = jan,
  journal = {Current Biology},
  volume = {34},
  number = {2},
  pages = {444-450.e5},
  issn = {09609822},
  doi = {10.1016/j.cub.2023.12.019},
  urldate = {2026-02-26},
  abstract = {The appreciation of music is a universal trait of humankind.1--3 Evidence supporting this notion includes the ubiquity of music across cultures4--7 and the natural predisposition toward music that humans display early in development.8--10 Are we musical animals because of species-specific predispositions? This question cannot be answered by relying on cross-cultural or developmental studies alone, as these cannot rule out enculturation.11 Instead, it calls for cross-species experiments testing whether homologous neural mechanisms underlying music perception are present in non-human primates. We present music to two rhesus monkeys, reared without musical exposure, while recording electroencephalography (EEG) and pupillometry. Monkeys exhibit higher engagement and neural encoding of expectations based on the previously seeded musical context when passively listening to real music as opposed to shuffled controls. We then compare human and monkey neural responses to the same stimuli and find a species-dependent contribution of two fundamental musical features---pitch and timing12---in generating expectations: while timing- and pitch-based expectations13 are similarly weighted in humans, monkeys rely on timing rather than pitch. Together, these results shed light on the phylogeny of music perception. They highlight monkeys' capacity for processing temporal structures beyond plain acoustic processing, and they identify a species-dependent contribution of time- and pitch-related features to the neural encoding of musical expectations.},
  langid = {english},
  file = {/Users/jellevanderwerff/Zotero/storage/7Q7LM6WR/Bianco et al. - 2024 - Neural encoding of musical expectations in a non-h.pdf}
}

@article{biancoNeuralEncodingMusical2025,
  title = {Neural Encoding of Musical Expectations in a Non-Human Primate},
  author = {Bianco, Roberta and Zuk, Nathaniel J. and Bigand, F{\'e}lix and Quarta, Eros and Grasso, Stefano and Arnese, Flavia and Ravignani, Andrea and {Battaglia-Mayer}, Alexandra and Novembre, Giacomo},
  year = 2025,
  month = feb,
  journal = {Current Biology},
  volume = {35},
  number = {3},
  pages = {708},
  publisher = {Elsevier},
  issn = {09609822},
  doi = {10.1016/j.cub.2025.01.015},
  urldate = {2026-02-26},
  langid = {english},
  file = {/Users/jellevanderwerff/Zotero/storage/V4GCM6YW/Bianco et al. - 2025 - Neural encoding of musical expectations in a non-human primate.html}
}

@article{burchardtToolkitDynamicStudy2024,
  title = {A Toolkit for the Dynamic Study of Air Sacs in Siamang and Other Elastic Circular Structures},
  author = {Burchardt, Lara S. and Van De Sande, Yana and Kehy, Mounia and Gamba, Marco and Ravignani, Andrea and Pouw, Wim},
  editor = {Lameira, Adriano},
  year = 2024,
  month = jun,
  journal = {PLOS Computational Biology},
  volume = {20},
  number = {6},
  pages = {e1012222},
  publisher = {Public Library of Science San Francisco, CA USA},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1012222},
  urldate = {2026-02-26},
  abstract = {Biological structures are defined by rigid elements, such as bones, and elastic elements, like muscles and membranes. Computer vision advances have enabled automatic tracking of moving animal skeletal poses. Such developments provide insights into complex time-varying dynamics of biological motion. Conversely, the elastic soft-tissues of organisms, like the nose of elephant seals, or the buccal sac of frogs, are poorly studied and no computer vision methods have been proposed. This leaves major gaps in different areas of biology. In primatology, most critically, the function of air sacs is widely debated; many open questions on the role of air sacs in the evolution of animal communication, including human speech, remain unanswered. To support the dynamic study of soft-tissue structures, we present a toolkit for the automated tracking of semi-circular elastic structures in biological video data. The toolkit contains unsupervised computer vision tools (using Hough transform) and supervised deep learning (by adapting DeepLabCut) methodology to track inflation of laryngeal air sacs or other biological spherical objects (e.g., gular cavities). Confirming the value of elastic kinematic analysis, we show that air sac inflation correlates with acoustic markers that likely inform about body size. Finally, we present a pre-processed audiovisual-kinematic dataset of 7+ hours of closeup audiovisual recordings of siamang (               Symphalangus syndactylus               ) singing. This toolkit (               https://github.com/WimPouw/AirSacTracker               ) aims to revitalize the study of non-skeletal morphological structures across multiple species.},
  langid = {english},
  file = {/Users/jellevanderwerff/Zotero/storage/ZV9CF8UV/Burchardt et al. - 2024 - A toolkit for the dynamic study of air sacs in siamang and other elastic circular structures.pdf}
}

@article{degregorioIsochronousSinging32024,
  title = {Isochronous Singing in 3 Crested Gibbon Species ( {{{\emph{Nomascus}}}} Spp.)},
  author = {De Gregorio, Chiara and Raimondi, Teresa and Bevilacqua, Valeria and Pertosa, Chiara and Valente, Daria and Carugati, Filippo and Bandoli, Francesca and Favaro, Livio and Lefaux, Brice and Ravignani, Andrea and Gamba, Marco},
  editor = {Hare, James},
  year = 2024,
  month = jul,
  journal = {Current Zoology},
  volume = {70},
  number = {3},
  pages = {291--297},
  publisher = {Oxford University Press UK},
  issn = {1674-5507, 2396-9814},
  doi = {10.1093/cz/zoad029},
  urldate = {2026-02-26},
  abstract = {Abstract             The search for common characteristics between the musical abilities of humans and other animal species is still taking its first steps. One of the most promising aspects from a comparative point of view is the analysis of rhythmic components, which are crucial features of human communicative performance but also well-identifiable patterns in the vocal displays of other species. Therefore, the study of rhythm is becoming essential to understand the mechanisms of singing behavior and the evolution of human communication. Recent findings provided evidence that particular rhythmic structures occur in human music and some singing animal species, such as birds and rock hyraxes, but only 2 species of nonhuman primates have been investigated so far (Indri indri and Hylobates lar). Therefore, our study aims to consistently broaden the list of species studied regarding the presence of rhythmic categories. We investigated the temporal organization in the singing of 3 species of crested gibbons (Nomascus gabriellae, Nomascus leucogenys, and Nomascus siki) and found that the most prominent rhythmic category was isochrony. Moreover, we found slight variation in songs' tempo among species, with N. gabriellae and N. siki singing with a temporal pattern involving a gradually increasing tempo (a musical accelerando), and N. leucogenys with a more regular pattern. Here, we show how the prominence of a peak at the isochrony establishes itself as a shared characteristic in the small apes considered so far.},
  copyright = {https://creativecommons.org/licenses/by-nc/4.0/},
  langid = {english}
}

@article{degregorioIsochronyAncestralCondition2024,
  title = {Isochrony as Ancestral Condition to Call and Song in a Primate},
  author = {De Gregorio, Chiara and Maiolini, Marco and Raimondi, Teresa and Carugati, Filippo and Miaretsoa, Longondraza and Valente, Daria and Torti, Valeria and Giacoma, Cristina and Ravignani, Andrea and Gamba, Marco},
  year = 2024,
  month = jul,
  journal = {Annals of the New York Academy of Sciences},
  volume = {1537},
  number = {1},
  pages = {41--50},
  issn = {0077-8923, 1749-6632},
  doi = {10.1111/nyas.15151},
  urldate = {2026-02-26},
  abstract = {Abstract                            Animal songs differ from calls in function and structure, and have comparative and translational value, showing similarities to human music. Rhythm in music is often distributed in quantized classes of intervals known as rhythmic categories. These classes have been found in the songs of a few nonhuman species but never in their calls. Are rhythmic categories song-specific, as in human music, or can they transcend the song--call boundary? We analyze the vocal displays of one of the few mammals producing both songs and call sequences:               Indri indri               . We test whether rhythmic categories (a) are conserved across songs produced in different contexts, (b) exist in call sequences, and (c) differ between songs and call sequences. We show that rhythmic categories occur across vocal displays. Vocalization type and function modulate deployment of categories. We find isochrony (1:1 ratio, like the rhythm of a ticking clock) in all song types, but only advertisement songs show three rhythmic categories (1:1, 1:2, 2:1 ratios). Like songs, some call types are also isochronous. Isochrony is the backbone of most indri vocalizations, unlike human speech, where it is rare. In indri, isochrony underlies both songs and hierarchy-less call sequences and might be ancestral to both.},
  langid = {english},
  file = {/Users/jellevanderwerff/Zotero/storage/48ZG74ZA/De Gregorio et al. - 2024 - Isochrony as ancestral condition to call and song in a primate.pdf}
}

@article{distefanoTestingHypothesesMajor2025,
  title = {Testing Hypotheses on the Major/Minor Dichotomy: Movement, Consonance/Dissonance, and (the Lack of) Cross-Species Evidence. {{Comment}} on ``the Major-Minor Mode Dichotomy in Music Perception'' by Giulio Carraturo, Victor Pando-Naude, Marco Costa, Peter Vuust, Leonardo Bonetti, Elvira Brattico},
  shorttitle = {Testing Hypotheses on the Major/Minor Dichotomy},
  author = {Di Stefano, Nicola and Ravignani, Andrea},
  year = 2025,
  month = sep,
  journal = {Physics of Life Reviews},
  volume = {54},
  pages = {3--4},
  issn = {15710645},
  doi = {10.1016/j.plrev.2025.05.001},
  urldate = {2026-02-26},
  langid = {english},
  file = {/Users/jellevanderwerff/Zotero/storage/LHQW96SS/Di Stefano e Ravignani - 2025 - Testing hypotheses on the majorminor dichotomy movement, consonancedissonance, and (the lack of).html}
}

@article{duengenAnecdotalObservationsSocially2024,
  title = {Anecdotal Observations of Socially Learned Vocalizations in Harbor Seals},
  author = {Duengen, Diandra and Polotzek, Martin and O'Sullivan, Eoin and Ravignani, Andrea},
  year = 2024,
  month = nov,
  journal = {Animal Behavior and Cognition},
  volume = {11},
  number = {4},
  pages = {393--403},
  issn = {23724323},
  doi = {10.26451/abc.11.04.04.2024},
  urldate = {2026-02-26},
  abstract = {Harbor seals (Phoca vitulina) are more solitary than many other pinnipeds. Yet, they are capable of vocal learning, a form of social learning. Most extant literature examines social animals when investigating social learning, despite sociality not being a prerequisite. Here, we report two formerly silent harbor seals who initiated vocalizations, after having repeatedly observed a conspecific receiving food rewards for vocalizing. Our observations suggest both social and vocal learning in a group of captive harbor seals, a species that lives semi-solitarily in the wild. We propose that, in this case, social learning acted as a shortcut to acquiring food rewards compared to the comparatively costly asocial learning.},
  langid = {english}
}

@article{duengenHarborSealPhoca2025,
  title = {A Harbor Seal (Phoca Vitulina) Shows Extensive Respiratory Control in Sound Production},
  author = {Duengen, Diandra and Jadoul, Yannick and Ravignani, Andrea},
  year = 2025,
  month = sep,
  journal = {BMC Ecology and Evolution},
  volume = {25},
  number = {1},
  pages = {90},
  issn = {2730-7182},
  doi = {10.1186/s12862-025-02404-9},
  urldate = {2026-02-26},
  langid = {english}
}

@misc{duengenTrainingExperimentallyNaive2024,
  title = {Training Experimentally Naive Seals for Vocal Learning Experiments},
  author = {Duengen, Diandra and Ravignani, Andrea},
  year = 2025,
  month = jul,
  publisher = {Cold Spring Harbor Laboratory},
  doi = {10.1101/2024.08.27.609954},
  urldate = {2026-02-26},
  abstract = {Harbor seals (Phoca vitulina) are a common zoo species that show a scientifically valuable propensity for vocal learning. Under human care, the seals can be trained to associate vocalizations with cues. This ability is termed vocal usage learning and is characterized by learning to use a vocalization in a specific context. Among mammals, seals are prime candidates to investigate vocal learning. Yet, only a handful of reports exist on harbor seal vocal learning abilities, and even fewer document how these were trained or tested. Here, we investigate how, and if, two experimentally naive harbor seals under human care can be trained to participate in scientific experiments. We describe the training and testing of two seals in two basic vocal learning experiments. We trained the animals to vocalize upon the presentation of discriminative stimuli (SD) through operant conditioning methods and tested their abilities to i) vocalize and refrain from vocalizing on two distinct SD's, and ii) produce two different vocalizations upon the presentation of two different SD's. Both seals learned the tasks: the first task was achieved within 118 trials (22 errors to criterion) and 220 trials (40 errors to criterion), the second task within 480 trials (158 errors to criterion) and 380 trials (94 errors to criterion), respectively. Our results confirm that harbor seals are capable of vocal usage learning and further suggest that associating individually distinct vocalizations with different SD's may be more cognitively demanding than vocalizing and being silent on SD.},
  archiveprefix = {Cold Spring Harbor Laboratory},
  copyright = {\copyright{} 2025, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NoDerivs 4.0 International), CC BY-ND 4.0, as described at http://creativecommons.org/licenses/by-nd/4.0/},
  langid = {english},
  file = {/Users/jellevanderwerff/Zotero/storage/SKASG8QB/Duengen e Ravignani - 2024 - Training experimentally naive seals for vocal learning experiments.pdf}
}

@article{duengenVocalUsageLearning2024,
  title = {Vocal Usage Learning and Vocal Comprehension Learning in Harbor Seals},
  author = {Duengen, Diandra and Jadoul, Yannick and Ravignani, Andrea},
  year = 2024,
  month = oct,
  journal = {BMC Neuroscience},
  volume = {25},
  number = {1},
  pages = {48--62},
  issn = {1471-2202},
  doi = {10.1186/s12868-024-00899-4},
  urldate = {2026-02-26},
  abstract = {Abstract                            Background                                Which mammals show vocal learning abilities, e.g., can learn new sounds, or learn to use sounds in new contexts? Vocal usage and comprehension learning are submodules of vocal learning. Specifically, vocal usage learning is the ability to learn to use a vocalization in a new context; vocal comprehension learning is the ability to comprehend a vocalization in a new context. Among mammals, harbor seals (                 Phoca vitulina                 ) are good candidates to investigate vocal learning. Here, we test whether harbor seals are capable of vocal usage and comprehension learning.                                                        Results               We trained two harbor seals to (i) switch contexts from a visual to an auditory cue. In particular, the seals first produced two vocalization types in response to two hand signs; they then transitioned to producing these two vocalization types upon the presentation of two distinct sets of playbacks of their own vocalizations. We then (ii) exposed the seals to a combination of trained and novel vocalization stimuli. In a final experiment, (iii) we broadcasted only novel vocalizations of the two vocalization types to test whether seals could generalize from the trained set of stimuli to only novel items of a given vocal category. Both seals learned all tasks and took\,{$\leq$}\,16 sessions to succeed across all experiments. In particular, the seals showed contextual learning through switching the context from former visual to novel auditory cues, vocal matching and generalization. Finally, by responding to the played-back vocalizations with distinct vocalizations, the animals showed vocal comprehension learning.                                         Conclusions               It has been suggested that harbor seals are vocal learners; however, to date, these observations had not been confirmed in controlled experiments. Here, through three experiments, we could show that harbor seals are capable of both vocal usage and comprehension learning.},
  langid = {english},
  file = {/Users/jellevanderwerff/Zotero/storage/6QCBS9NU/Duengen et al. - 2024 - Vocal usage learning and vocal comprehension learning in harbor seals.pdf}
}

@article{eleuteriChimpanzeeDrummingShows2025,
  included = {true},
  title = {Chimpanzee Drumming Shows Rhythmicity and Subspecies Variation},
  author = {Eleuteri, Vesta and {van der Werff}, Jelle and Wilhelm, Wytse and Soldati, Adrian and Crockford, Catherine and Desai, Nisarg and Fedurek, Pawel and Fitzgerald, Maegan and Graham, Kirsty E. and Koops, Kathelijne and Pruetz, Jill and Samuni, Liran and Slocombe, Katie and Stoeger, Angela and Wilson, Michael L. and Wittig, Roman M. and Zuberb{\"u}hler, Klaus and Camara, Henry D. and Mamy, Gnan and Ravignani, Andrea and Hobaiter, Catherine},
  year = 2025,
  month = may,
  journal = {Current Biology},
  volume = {35},
  number = {10},
  pages = {2448-2456.e4},
  publisher = {Elsevier},
  issn = {09609822},
  doi = {10.1016/j.cub.2025.04.019},
  urldate = {2026-02-26},
  langid = {english},
  pmid = {40347944},
  keywords = {chimpanzee drumming,chimpanzees,drumming,music,regional variation},
  file = {/Users/jellevanderwerff/Zotero/storage/QJXID7VJ/Eleuteri et al. - 2025 - Chimpanzee drumming shows rhythmicity and subspecies variation.pdf}
}

@article{francesconiSEXBonobosIntensity2026,
  included = {true},
  title = {{{SEX}} in Bonobos: The Intensity of Sexual Stimulation Sharply Drops after Facial Mimicry},
  shorttitle = {{{SEX}} in Bonobos},
  author = {Francesconi, Martina and Galotti, Alice and Jadoul, Yannick and Giovannini, Federico and Ravignani, Andrea and Palagi, Elisabetta},
  year = 2026,
  month = jan,
  journal = {Evolution and Human Behavior},
  volume = {47},
  number = {1},
  pages = {106786},
  publisher = {Elsevier},
  issn = {10905138},
  doi = {10.1016/j.evolhumbehav.2025.106786},
  urldate = {2026-02-26},
  langid = {english}
}

@inproceedings{franzonEffectsAnimacyProcessing2017,
  title = {Effects of Animacy on the Processing of Morphological Number: A Cognitive Inheritance? {{A}} Psycholinguistic Study},
  shorttitle = {Effects of Animacy on the Processing of Morphological Number},
  booktitle = {{{BOOK OF ABSTRACTS}}},
  author = {Franzon, Francesca and Rugani, Rosa and Giomo, Dunia and Zanini, Chiara},
  year = 2017,
  pages = {742},
  urldate = {2026-02-26},
  langid = {english},
  file = {/Users/jellevanderwerff/Zotero/storage/CKZ797LL/Franzon et al. - 2017 - Effects of animacy on the processing of morphological number a cognitive inheritance A psycholingu.pdf}
}

@incollection{franzonInterferenceAnimacyProcessing2017,
  title = {The Interference of Animacy in the Processing of Morphological Number},
  booktitle = {10th International Morphological Processing Conference ({{MoProc}})},
  author = {Franzon, F. and Zanini, C. and Giomo, D. and Peressotti, F. and Rugani, R.},
  year = 2017,
  urldate = {2026-02-26},
  abstract = {none},
  langid = {english}
}

@article{giomoGlobalLocalDeviance2026,
  title = {Global and Local Deviance Effects in the Processing of Temporal Patterns},
  author = {Giomo, Dunia and Brasselet, Romain and Fortunato, Gianfranco and Bueti, Domenica},
  year = 2026,
  month = feb,
  journal = {Annals of the New York Academy of Sciences},
  volume = {1556},
  number = {1},
  pages = {e70173},
  issn = {0077-8923, 1749-6632},
  doi = {10.1111/nyas.70173},
  urldate = {2026-02-26},
  abstract = {ABSTRACT             Perceptual and sensorimotor events are often experienced as temporal patterns, that is, identified as sequences based on their temporal features. While current timing models propose separate mechanisms supporting the processing of single intervals and temporal patterns, they leave partially unclear whether the latter entails the processing of both individual intervals and the overall structure of a pattern, or only one of these features. Here, we narrowed this question down by investigating how violations of regularity within the individual intervals of a temporal sequence (i.e., local violations) and in its overall structure (i.e., global violations) differentially affect its reproduction. We tested these violation effects in three experiments in which the sequences were experienced either in the visual or auditory domain and had either simple or complex structures. Results showed that the precision in reproducing simple visual and auditory patterns was primarily affected by local violations, whereas global violations mostly impacted the reproduction of visual patterns with complex structures. These detrimental effects were partially explained by rescaling and bias effects in the reproduced patterns. Overall, our findings indicate that the processing and reproduction of temporal patterns differentially weigh individual intervals and global structure, depending on sensory modality and, for visual patterns, on structural complexity.           ,              Our experience of the world is inherently structured by temporal patterns. Yet a full understanding of how we process such patterns is still lacking. Across three finger-tapping experiments employing the local--global paradigm, we show that the processing and reproduction of temporal patterns rely on a differential weighting of their individual elements and overall structure. This weighting depends on both the structural complexity of the patterns and the sensory modality in which they are experienced.},
  langid = {english}
}

@article{giomoProcessingLearningTemporal2022,
  title = {The Processing and Learning of Temporal Patterns: From Behaviour to Computational Models},
  shorttitle = {The Processing and Learning of Temporal Patterns},
  author = {Giomo, Dunia},
  year = 2022,
  month = sep,
  pages = {1--110},
  publisher = {ITA},
  urldate = {2026-02-26},
  abstract = {open},
  langid = {english},
  file = {/Users/jellevanderwerff/Zotero/storage/HNYXFQDQ/Giomo - 2022 - The processing and learning of temporal patterns from behaviour to computational models.pdf}
}

@inproceedings{giomoSensorimotorSynchronizationTemporal2019,
  title = {Sensorimotor Synchronization and Temporal Order Judgements Reveal Saccadic Temporal Recalibration},
  booktitle = {{{PERCEPTION}}},
  author = {Giomo, Dunia and Parsons, Brent and Bueti, Domenica},
  year = 2019,
  volume = {48},
  pages = {148--148},
  publisher = {SAGE PUBLICATIONS LTD 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND},
  urldate = {2026-02-26},
  langid = {english},
  file = {/Users/jellevanderwerff/Zotero/storage/LDAPRZF3/Giomo et al. - 2019 - Sensorimotor synchronization and temporal order judgements reveal saccadic temporal recalibration.html}
}

@inproceedings{goncharovaHarbourSealsCan2024,
  title = {Harbour Seals Can Articulate to Modulate Formants},
  booktitle = {The {{IMPRS Conference}} 2024},
  author = {Goncharova, Maria V. and Jadoul, Yannick and Reichmuth, Colleen and Tecumseh Fitch, W. and Ravignani, Andrea},
  year = 2024,
  urldate = {2026-02-26},
  langid = {english}
}

@article{goncharovaVocalTractDynamics2024,
  title = {Vocal Tract Dynamics Shape the Formant Structure of Conditioned Vocalizations in a Harbor Seal},
  author = {Goncharova, Maria and Jadoul, Yannick and Reichmuth, Colleen and Fitch, W. Tecumseh and Ravignani, Andrea},
  year = 2024,
  month = aug,
  journal = {Annals of the New York Academy of Sciences},
  volume = {1538},
  number = {1},
  pages = {107--116},
  issn = {0077-8923, 1749-6632},
  doi = {10.1111/nyas.15189},
  urldate = {2026-02-26},
  abstract = {Abstract                            Formants, or resonance frequencies of the upper vocal tract, are an essential part of acoustic communication. Articulatory gestures---such as jaw, tongue, lip, and soft palate movements---shape formant structure in human vocalizations, but little is known about how nonhuman mammals use those gestures to modify formant frequencies. Here, we report a case study with an adult male harbor seal trained to produce an arbitrary vocalization composed of multiple repetitions of the sound               wa               . We analyzed jaw movements frame-by-frame and matched them to the tracked formant modulation in the corresponding vocalizations. We found that the jaw opening angle was strongly correlated with the first (F1) and, to a lesser degree, with the second formant (F2). F2 variation was better explained by the jaw angle opening when the seal was lying on his back rather than on the belly, which might derive from soft tissue displacement due to gravity. These results show that harbor seals share some common articulatory traits with humans, where the F1 depends more on the jaw position than F2. We propose further in vivo investigations of seals to further test the role of the tongue on formant modulation in mammalian sound production.},
  langid = {english},
  file = {/Users/jellevanderwerff/Zotero/storage/3ZZCI2ZG/Goncharova et al. - 2024 - Vocal tract dynamics shape the formant structure of conditioned vocalizations in a harbor seal.pdf}
}

@article{hartmannDelineatingFieldLanguage2024,
  title = {Delineating the Field of Language Evolution Research: A Quantitative Analysis of Peer-Review Patterns at the Joint Conference on Language Evolution ({{JCoLE}} 2022)},
  shorttitle = {Delineating the Field of Language Evolution Research},
  author = {Hartmann, Stefan and Wacewicz, S{\l}awomir and Ravignani, Andrea and Valente, Daria and Rodrigues, Evelina Daniela and Asano, Rie and Jadoul, Yannick},
  year = 2024,
  month = jun,
  journal = {Interaction Studies. Social Behaviour and Communication in Biological and Artificial Systems},
  volume = {25},
  number = {1},
  pages = {101--117},
  issn = {1572-0373, 1572-0381},
  doi = {10.1075/is.00024.har},
  urldate = {2026-02-26},
  abstract = {Abstract             Research on language evolution is an established subject area yet permeated by terminological controversies about          which topics should be considered pertinent to the field and which not. By consequence, scholars focusing on language evolution           struggle in providing precise demarcations of the discipline, where even the very central notions of evolution and language are           elusive. We aimed at providing a data-driven characterisation of language evolution as a field of research by relying on          quantitative analysis of data drawn from 697 reviews on 255 submissions from the Joint Conference on Language Evolution 2022          (Kanazawa, Japan). Our results delineate a field characterized by a core of main research topics such as iconicity, sign language,          multimodality. Despite being explored within the framework of language evolution research, only very recently these topics became           popular in linguistics. As a result, language evolution has the potential to emerge as a forefront of linguistic research,          bringing innovation to the study of language. We also see the emergence of more recent topics like rhythm, music, and vocal           learning. Furthermore, the community identifies cognitive science, primatology, archaeology, palaeoanthropology, and genetics as          key areas, encouraging empirical rather than theoretical work. With new themes, models, and methodologies emerging, our results           depict an intrinsically multidisciplinary and evolving research field, likely adapting as language itself.},
  copyright = {https://benjamins.com/content/customers/rights},
  langid = {english},
  file = {/Users/jellevanderwerff/Zotero/storage/KZNSYKVZ/Hartmann et al. - 2024 - Delineating the field of language evolution research a quantitative analysis of peer-review pattern.pdf}
}

@article{hershAccelerandoCrescendoAfrican2025,
  title = {Accelerando and Crescendo in {{African}} Penguin Ecstatic Display Songs},
  author = {Hersh, Taylor A. and Jadoul, Yannick and Gamba, Marco and Ravignani, Andrea and Favaro, Livio},
  year = 2025,
  month = jul,
  journal = {Annals of the New York Academy of Sciences},
  volume = {1549},
  number = {1},
  pages = {112--119},
  issn = {0077-8923, 1749-6632},
  doi = {10.1111/nyas.15383},
  urldate = {2026-02-26},
  abstract = {Abstract                            Many species produce rhythmic sound sequences. Some purportedly speed up their vocalizations throughout a display, reminiscent of---but not necessarily equivalent to---               accelerando               in human music. This phenomenon has been frequently reported but rarely quantified, which limits our ability to understand its mechanism, function, and evolution. Here, we use a suite of rhythm analyses to quantify temporal and acoustic features in the ecstatic display songs of male African penguins (               Spheniscus demersus               ). We show that songs get faster (i.e., accelerando) and louder (i.e., crescendo) as they progress. The accelerando occurs because the intersyllable silences, not the syllables themselves, predictably shorten over time. This rhythmicity is maintained even when individuals take audible breaths. Individuals also show plasticity: when they start with a slow tempo, they speed up more strongly than when they start with a fast tempo. We hypothesize that this well-timed accelerando may stem from arousal-based mechanisms, biomechanical constraints, or more complex rhythmic control. Future work should test the mechanisms behind this intra-individual rhythmic variation since nonpasserine birds are thought to have limited vocal plasticity. By integrating a rich empirical dataset with cutting-edge rhythm analyses, we establish the necessary foundation to determine how such features evolved and their role(s) across communication systems.},
  langid = {english}
}

@article{hershCetaceansAreNext2024,
  title = {Cetaceans Are the next Frontier for Vocal Rhythm Research},
  author = {Hersh, Taylor A. and Ravignani, Andrea and Whitehead, Hal},
  year = 2024,
  month = jun,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {121},
  number = {25},
  pages = {e2313093121},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.2313093121},
  urldate = {2026-02-26},
  abstract = {While rhythm can facilitate and enhance many aspects of behavior, its evolutionary trajectory in vocal communication systems remains enigmatic. We can trace evolutionary processes by investigating rhythmic abilities in different species, but research to date has largely focused on songbirds and primates. We present evidence that cetaceans---whales, dolphins, and porpoises---are a missing piece of the puzzle for understanding why rhythm evolved in vocal communication systems. Cetaceans not only produce rhythmic vocalizations but also exhibit behaviors known or thought to play a role in the evolution of different features of rhythm. These behaviors include vocal learning abilities, advanced breathing control, sexually selected vocal displays, prolonged mother--infant bonds, and behavioral synchronization. The untapped comparative potential of cetaceans is further enhanced by high interspecific diversity, which generates natural ranges of vocal and social complexity for investigating various evolutionary hypotheses. We show that rhythm (particularly isochronous rhythm, when sounds are equally spaced in time) is prevalent in cetacean vocalizations but is used in different contexts by baleen and toothed whales. We also highlight key questions and research areas that will enhance understanding of vocal rhythms across taxa. By coupling an infraorder-level taxonomic assessment of vocal rhythm production with comparisons to other species, we illustrate how broadly comparative research can contribute to a more nuanced understanding of the prevalence, evolution, and possible functions of rhythm in animal communication.},
  langid = {english},
  file = {/Users/jellevanderwerff/Zotero/storage/SIV2EPBX/Hersh et al. - 2024 - Cetaceans are the next frontier for vocal rhythm research.pdf}
}

@article{jadoulEvolutionaryModelRhythmic2025,
  title = {An Evolutionary Model of Rhythmic Accelerando in Animal Vocal Signalling},
  author = {Jadoul, Yannick and Hersh, Taylor A. and Fern{\'a}ndez Domingos, Elias and Gamba, Marco and Favaro, Livio and Ravignani, Andrea},
  editor = {Chen, Xingru},
  year = 2025,
  month = apr,
  journal = {PLOS Computational Biology},
  volume = {21},
  number = {4},
  pages = {e1013011},
  publisher = {Public Library of Science San Francisco, CA USA},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1013011},
  urldate = {2026-02-26},
  abstract = {Animal acoustic communication contains many structural features. Among these, temporal structure, or rhythmicity, is increasingly tested empirically and modelled quantitatively. Accelerando is a rhythmic structure which consists of temporal intervals increasing in rate over a sequence. Why this particular vocal behaviour is widespread in many different animal lineages, and how it evolved, is so far unknown. Here, we use evolutionary game theory and computer simulations to link two rhythmic aspects of animal communication, acceleration and overlap: We test whether rhythmic accelerando could evolve under a pressure for acoustic overlap in time. Our models show that higher acceleration values result in a higher payoff, driven by the higher relative overlap between sequences. The addition of a cost to the payoff matrix models a physiological disadvantage to high acceleration rates and introduces a divergence between an individual's incentive and the overall payoff of the population. Analysis of the invasion dynamics of acceleration strategies shows a stable, non-invadable range of strategies for moderate acceleration levels. Our computational simulations confirm these results: A simple selective pressure to maximise the expected overlap, while minimising the associated physiological cost, causes an initially isochronous population to evolve towards producing increasingly accelerating sequences until a population-wide equilibrium of rhythmic accelerando is reached. These results are robust to a broad range of parameter values. Overall, our analyses show that if overlap is beneficial, emergent evolutionary dynamics allow a population to gradually start producing accelerating sequences and reach a stable state of moderate acceleration. Finally, our modelling results closely match empirical data recorded from an avian species showing rhythmic accelerando, the African penguin. This shows the productive interplay between theoretical and empirical biology.},
  langid = {english}
}

@article{jadoulHiddenAssumptionsInteger2025a,
  title = {Hidden Assumptions of Integer Ratio Analyses in Bioacoustics and Music},
  author = {Jadoul, Yannick and Tufarelli, Tommaso and Coissac, Chlo{\'e} and Gamba, Marco and Ravignani, Andrea},
  year = 2025,
  month = nov,
  journal = {Annals of the New York Academy of Sciences},
  volume = {1553},
  number = {1},
  pages = {363--378},
  issn = {0077-8923, 1749-6632},
  doi = {10.1111/nyas.70037},
  urldate = {2026-02-26},
  abstract = {Abstract             Rhythm is ubiquitous in human culture and in nature, but hard to capture in all its complexity. A key dimension of rhythm, integer ratio categories occur when the relationship between temporal intervals can be expressed as small-integer ratios. Recent work has found integer ratio categories in most human musical cultures and some animal species' vocalizations or behavioral displays. But biological systems are noisy, and empirically measured intervals rarely form an exact small-integer ratio. Here, we mathematically assess whether a leading integer ratio analysis method makes valid statistical and biological assumptions. In particular, we (1) make the temporal properties of empirical ratios explicit, both in general and for the typical use in the literature; (2) show how the choice of ratio formula affects the probability distribution of rhythm ratios and ensuing statistical results; (3) guide the reader to carefully consider the assumptions and null hypotheses of the statistical analysis; and (4) present a comprehensive methodology to statistically test integer ratios for any null hypothesis of choice. Our observations have implications for both past and future research in music cognition and animal behavior: They suggest how to interpret past findings and provide tools to choose the correct null hypotheses in future empirical~work.},
  langid = {english},
  file = {/Users/jellevanderwerff/Zotero/storage/XQ7QRGKA/Jadoul et al. - 2025 - Hidden assumptions of integer ratio analyses in bioacoustics and music.pdf}
}

@article{jadoulParselmouthBioacousticsAutomated2023,
  title = {Parselmouth for Bioacoustics: Automated Acoustic Analysis in Python},
  shorttitle = {Parselmouth for Bioacoustics},
  author = {Jadoul, Yannick and De Boer, Bart and Ravignani, Andrea},
  year = 2024,
  month = jan,
  journal = {Bioacoustics},
  volume = {33},
  number = {1},
  pages = {1--19},
  publisher = {Taylor \& Francis},
  issn = {0952-4622, 2165-0586},
  doi = {10.1080/09524622.2023.2259327},
  urldate = {2026-02-26},
  abstract = {Bioacoustics increasingly relies on large datasets and computational methods. The need to batch-process large amounts of data and the increased focus on algorithmic processing require software tools. To optimally assist in a bioacoustician's workflow, software tools need to be as simple and effective as possible. Five years ago, the Python package Parselmouth was released to provide easy and intuitive access to all functionality in the Praat software. Whereas Praat is principally designed for phonetics and speech processing, plenty of bioacoustics studies have used its advanced acoustic algorithms. Here, we evaluate existing usage of Parselmouth and discuss in detail several studies which used the software library. We argue that Parselmouth has the potential to be used even more in bioacoustics research, and suggest future directions to be pursued with the help of Parselmouth.},
  langid = {english},
  keywords = {Acoustic analysis,data processing,Praat,Python,software},
  file = {/Users/jellevanderwerff/Zotero/storage/GEKL6HCP/Jadoul et al. - 2023 - Parselmouth for bioacoustics automated acoustic a.pdf;/Users/jellevanderwerff/Zotero/storage/XMDS8YU7/Jadoul et al. - 2024 - Parselmouth for bioacoustics automated acoustic analysis in python.pdf}
}

@article{jadoulRhythmicAnalysisAnimal2025,
  title = {Rhythmic Analysis in Animal Communication, Speech, and Music: The Normalized Pairwise Variability Index Is a Summary Statistic of Rhythm Ratios},
  shorttitle = {Rhythmic Analysis in Animal Communication, Speech, and Music},
  author = {Jadoul, Yannick and D'Orazio, Francesca and Eleuteri, Vesta and {van der Werff}, Jelle and Tufarelli, Tommaso and Gamba, Marco and Raimondi, Teresa and Ravignani, Andrea},
  year = 2025,
  month = mar,
  journal = {Vibration},
  volume = {8},
  number = {2},
  pages = {12--25},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2571-631X},
  doi = {10.3390/vibration8020012},
  urldate = {2026-02-26},
  abstract = {Rhythm is fundamental in many physical and biological systems. Rhythm is relevant to a broad range of phenomena across different fields, including animal bioacoustics, speech sciences, and music cognition. As a result, the interest in developing consistent quantitative measures for cross-disciplinary rhythmic analysis is growing. Two quantitative measures that can be directly applied to any temporal structure are the normalized pairwise variability index (nPVI) and rhythm ratios (rk). The nPVI summarizes the overall isochrony of a sequence, i.e., how regularly spaced a sequence's events are, as a single value. Meanwhile, rk quantifies ratios between a sequence's adjacent intervals and is often used for identifying rhythmic categories. Here, we show that these two rhythmic measures are fundamentally connected: the nPVI is a summary static of the rk values of a temporal sequence. This result offers a deeper understanding of how these measures are applied. It also opens the door for creating novel, custom measures to quantify rhythmic patterns based on a sequence's rk distribution and compare rhythmic patterns across different domains. The explicit connection between nPVI and rk is one further step towards a common quantitative toolkit for rhythm research across disciplines.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {bioacoustics,nPVI,rhythmic measures,temporal sequences,timing,vocalization},
  file = {/Users/jellevanderwerff/Zotero/storage/6QETHHJP/Jadoul et al. - 2025 - Rhythmic Analysis in Animal Communication, Speech, and Music The Normalized Pairwise Variability In.pdf}
}

@inproceedings{kakiharaLearningTransmissionRhythmic2024,
  title = {Learning and Transmission of Rhythmic Information Is Associated with Working Memory and Sensorimotor Synchronization Skill: The Neurosciences and Music {{VIII}}},
  shorttitle = {Learning and Transmission of Rhythmic Information Is Associated with Working Memory and Sensorimotor Synchronization Skill},
  booktitle = {The {{Neurosciences}} and {{Music VIII}}: {{Wiring}}, Re-Wiring, and Well-Being},
  author = {Kakihara, Marcelo and Martin, Mathilde and {van der Werff}, Jelle and Ravignani, Andrea and Fasano, Maria Celeste and Overgaard, Morten Storm and Keller, Peter and Lumaca, Massimo},
  year = 2024,
  month = jun,
  urldate = {2026-02-26},
  langid = {english}
}

@article{laffiRhythmHorseGaits2025,
  title = {The Rhythm of Horse Gaits},
  author = {Laffi, Lia and Raimondi, Teresa and Ferrante, Carola and Pagliara, Eleonora and Bertuglia, Andrea and Briefer, Elodie Floriane and Gamba, Marco and Ravignani, Andrea},
  year = 2025,
  month = jan,
  journal = {Annals of the New York Academy of Sciences},
  volume = {1543},
  number = {1},
  pages = {86--93},
  issn = {0077-8923, 1749-6632},
  doi = {10.1111/nyas.15271},
  urldate = {2026-02-26},
  abstract = {Abstract             What makes animal gaits so audibly rhythmic? To answer this question, we recorded the footfall sound of 19 horses and quantified the rhythmic differences in the temporal structure of three natural gaits: walk, trot, and canter. Our analyses show that each gait displays a strikingly specific rhythmic pattern and that all gaits are organized according to small-integer ratios, those found when adjacent temporal intervals are related by a mathematically simple relationship of integer numbers. Walk and trot exhibit an isochronous structure (1:1)---similar to a ticking clock---while canter is characterized by three small-integer ratios (1:1, 1:2, 2:1). While walk and trot both show isochrony, trot has a slower tempo and is more precise and accurate, like a metronome. Our results quantitatively discriminate horse gaits based on rhythm, revealing striking commonalities with human music and some animal communicative signals. Gait and vocal rhythmicity share key features, and the former likely predates the latter; we suggest this supports gait-based hypotheses for the evolution of rhythm. Specifically, the perception of locomotor rhythmicity may have evolved in different species under pressure for predator recognition and mate selection; it may have been later exapted for rhythmic vocal communication.},
  langid = {english},
  file = {/Users/jellevanderwerff/Zotero/storage/H3GDVRLF/Laffi et al. - 2025 - The rhythm of horse gaits.pdf}
}

@article{laffiRhythmicCategoriesHorse2025,
  title = {Rhythmic Categories in Horse Gait Kinematics},
  author = {Laffi, Lia and Bigand, F{\'e}lix and Peham, Christian and Novembre, Giacomo and Gamba, Marco and Ravignani, Andrea},
  year = 2025,
  month = mar,
  journal = {Journal of Anatomy},
  volume = {246},
  number = {3},
  pages = {456--465},
  issn = {0021-8782, 1469-7580},
  doi = {10.1111/joa.14200},
  urldate = {2026-02-26},
  abstract = {Abstract                            Anecdotally, horses' gaits sound rhythmic. Are they really? In this study, we quantified the motor rhythmicity of horses across three different gaits (walk, trot, and canter). For the first time, we adopted quantitative tools from bioacoustics and music cognition to quantify locomotor rhythmicity. Specifically, we tested whether kinematics data contained rhythmic categories; these occur when adjacent temporal intervals are categorically, rather than randomly, distributed. We extracted the motion cycle duration (t               k               ) of two ipsilateral hooves from motion data of 13 ridden horses and calculated the ratios from two successive t               k               values. We tested whether these ratios significantly fell within rhythmic categories and quantified how close they were to small-integer ratios, a rhythmic feature also present in animal vocalizations and human music. We found a strong isochronous pattern---a 1:1 rhythmic ratio, corresponding to the ticking of a clock---in the motion of single limbs for all gaits. We also analyzed the interlimb coordination of the two ipsilateral hooves' impacts to identify differences associated with the biomechanical patterns of the three gaits. We found an interlimb 1:1 rhythmic pattern for trot and 1:3 and 3:1 rhythmic categories for walk and canter. Our findings are a first step toward quantifying rhythmicity in horse locomotion and potentially the resulting rhythmic sounds, with possible implications as tools to detect gait irregularities. Overall, we show that rhythmic categories are a valuable tool for gait kinematic analysis and that they can be used to quantify temporal patterns in the motor domain.},
  copyright = {\copyright{} 2024 The Author(s). Journal of Anatomy published by John Wiley \& Sons Ltd on behalf of Anatomical Society.},
  langid = {english},
  keywords = {bioacoustics,integer ratios,isochrony,locomotion,rhythm},
  file = {/Users/jellevanderwerff/Zotero/storage/SWN3DLLD/Laffi et al. - 2025 - Rhythmic categories in horse gait kinematics.pdf;/Users/jellevanderwerff/Zotero/storage/HS3N83GN/joa.html}
}

@article{lameiraRecursiveSelfembeddedVocal2024,
  title = {Recursive Self-Embedded Vocal Motifs in Wild Orangutans},
  author = {Lameira, Adriano R and Hardus, Madeleine E and Ravignani, Andrea and Raimondi, Teresa and Gamba, Marco},
  year = 2024,
  month = jan,
  journal = {eLife},
  volume = {12},
  pages = {RP88348},
  publisher = {eLife Sciences Publications, Ltd},
  issn = {2050-084X},
  doi = {10.7554/eLife.88348},
  urldate = {2026-02-26},
  abstract = {Recursive procedures that allow placing a vocal signal inside another of a similar kind provide a neuro-computational blueprint for syntax and phonology in spoken language and human song. There are, however, no known vocal sequences among nonhuman primates arranged in self-embedded patterns that evince vocal recursion or potential incipient or evolutionary transitional forms thereof, suggesting a neuro-cognitive transformation exclusive to humans. Here, we uncover that wild flanged male orangutan long calls feature rhythmically isochronous call sequences nested within isochronous call sequences, consistent with two hierarchical strata. Remarkably, three temporally and acoustically distinct call rhythms in the lower stratum were not related to the overarching rhythm at the higher stratum by any low multiples, which suggests that these recursive structures were neither the result of parallel non-hierarchical procedures nor anatomical artifacts of bodily constraints or resonances. Findings represent a case of temporally recursive hominid vocal combinatorics in the absence of syntax, semantics, phonology, or music. Second-order combinatorics, `sequences within sequences', involving hierarchically organized and cyclically structured vocal sounds in ancient hominids may have preluded the evolution of recursion in modern language-able humans.           ,              Language is the most powerful communication tool known in nature. By combining a finite set of elements, it allows us to encode infinite messages. This enables communication about virtually anything, from alerting others to potential dangers, to recommending a favourite book. The prevailing theory of the last 70 years suggests that this ability rests on a computational process in the brain that is unique to humans, known as recursion.             Recursion enables humans to produce and place a language element or pattern of elements inside another element or pattern of the same kind. In this way, a clause can be embedded inside another `carrier' clause to extend a thought, argument, or scenario, for example, ``the dog, which chased the cat, was barking''. While recursion offers a simple, yet potent, explanation for the endless possibilities of language, how and why recursion -- and by extension language -- emerged in humans but no other animals remains a mystery.             Lameira et al. observed vocal patterns in wild orangutans that appeared to be composed of different elements. As orangutans and other great apes are our closest living relatives, they represent the most realistic model for studying the ability of human ancestors to use and comprehend language. Therefore, Lameira et al. set out to determine if this was a case of vocal patterning embedded within a similar vocal pattern, which could indicate that recursion underpins production of these calls.             Analysing recordings of long calls made by wild male orangutans showed that they are organized as two layers, where calls with a regular beat (or tempo) are produced within another ``carrier'' call of a different tempo. Up to three different call types, each with their own signature tempo, can occur within the same carrier call. Further analysis confirmed these call types were unrelated to the carrier.             The findings of Lameira et al. demonstrate that orangutans produce recursive vocal sequences that could represent a possible precursor to recursion in humans, offering a potential avenue for studying how recursion, and ultimately language, evolved in humans. In the future, better understanding of how language evolved may help to refine machine learning algorithms that aim to recognize, predict or generate text.},
  langid = {english},
  keywords = {call sequences,isochrony,orangutans,recursion,rhythm,vocal combinatorics},
  file = {/Users/jellevanderwerff/Zotero/storage/WVUB2CQC/Lameira et al. - 2024 - Recursive self-embedded vocal motifs in wild orangutans.pdf}
}

@article{leonettiCrossspeciesFrameworkClassifying2024,
  title = {A Cross-Species Framework for Classifying Sound-Movement Couplings},
  author = {Leonetti, Silvia and Ravignani, Andrea and Pouw, Wim},
  year = 2024,
  month = dec,
  journal = {Neuroscience \& Biobehavioral Reviews},
  volume = {167},
  pages = {105911},
  publisher = {Elsevier},
  issn = {01497634},
  doi = {10.1016/j.neubiorev.2024.105911},
  urldate = {2026-02-26},
  langid = {english}
}

@article{leonettiWhyDogsWag2024,
  title = {Why Do Dogs Wag Their Tails?},
  author = {Leonetti, Silvia and Cimarelli, Giulia and Hersh, Taylor A. and Ravignani, Andrea},
  year = 2024,
  month = jan,
  journal = {Biology Letters},
  volume = {20},
  number = {1},
  pages = {20230407},
  publisher = {The Royal Society},
  issn = {1744-957X},
  doi = {10.1098/rsbl.2023.0407},
  urldate = {2026-02-26},
  abstract = {Tail wagging is a conspicuous behaviour in domestic dogs (               Canis familiaris               ). Despite how much meaning humans attribute to this display, its quantitative description and evolutionary history are rarely studied. We summarize what is known about the mechanism, ontogeny, function and evolution of this behaviour. We suggest two hypotheses to explain its increased occurrence and frequency in dogs compared to other canids. During the domestication process, enhanced rhythmic tail wagging behaviour could have (i) arisen as a by-product of selection for other traits, such as docility and tameness, or (ii) been directly selected by humans, due to our proclivity for rhythmic stimuli. We invite testing of these hypotheses through neurobiological and ethological experiments, which will shed light on one of the most readily observed yet understudied animal behaviours. Targeted tail wagging research can be a window into both canine ethology and the evolutionary history of characteristic human traits, such as our ability to perceive and produce rhythmic behaviours.},
  langid = {english}
}

@article{lumacaFrontoparietalNetworkTopology2024,
  title = {Frontoparietal Network Topology as a Neural Marker of Musical Perceptual Abilities},
  author = {Lumaca, M. and Keller, P. E. and Baggio, G. and {Pando-Naude}, V. and Bajada, C. J. and Martinez, M. A. and Hansen, J. H. and Ravignani, A. and Joe, N. and Vuust, P. and Vuli{\'c}, K. and Sandberg, K.},
  year = 2024,
  month = sep,
  journal = {Nature Communications},
  volume = {15},
  number = {1},
  pages = {8160},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-024-52479-z},
  urldate = {2026-02-26},
  abstract = {Abstract             Why are some individuals more musical than others? Neither cognitive testing nor classical localizationist neuroscience alone can provide a complete answer. Here, we test how the interplay of brain network organization and cognitive function delivers graded perceptual abilities in a distinctively human capacity. We analyze multimodal magnetic resonance imaging, cognitive, and behavioral data from 200+ participants, focusing on a canonical working memory network encompassing prefrontal and posterior parietal regions. Using graph theory, we examine structural and functional frontoparietal network organization in relation to assessments of musical aptitude and experience. Results reveal a positive correlation between perceptual abilities and the integration efficiency of key frontoparietal regions. The linkage between functional networks and musical abilities is mediated by working memory processes, whereas structural networks influence these abilities through sensory integration. Our work lays the foundation for future investigations into the neurobiological roots of individual differences in musicality.},
  copyright = {2024 The Author(s)},
  langid = {english},
  keywords = {Network models,Perception},
  file = {/Users/jellevanderwerff/Zotero/storage/TN5GAJWI/Lumaca et al. - 2024 - Frontoparietal network topology as a neural marker.pdf}
}

@article{lynch5ConundrumEsophagogastric2025,
  title = {Issue Information},
  shorttitle = {5 the Conundrum of Esophagogastric Junction Outflow Obstruction},
  year = 2025,
  month = jul,
  journal = {Annals of the New York Academy of Sciences},
  volume = {1549},
  number = {1},
  pages = {1--3},
  issn = {0077-8923, 1749-6632},
  doi = {10.1111/nyas.15023},
  urldate = {2026-02-26},
  langid = {english}
}

@article{maldarelliChicksProduceConsonant2024,
  title = {Chicks Produce Consonant, Sometimes Jazzy, Sounds},
  author = {Maldarelli, Gianmarco and Dissegna, Andrea and Ravignani, Andrea and Chiandetti, Cinzia},
  year = 2024,
  month = sep,
  journal = {Biology Letters},
  volume = {20},
  number = {9},
  pages = {20240374},
  publisher = {The Royal Society},
  issn = {1744-9561, 1744-957X},
  doi = {10.1098/rsbl.2024.0374},
  urldate = {2026-02-26},
  abstract = {Several animal species prefer consonant over dissonant sounds, a building block of musical scales and harmony. Could consonance and dissonance be linked, beyond music, to the emotional valence of vocalizations? We extracted the fundamental frequency from calls of young chickens with either positive or negative emotional valence, i.e. contact, brood and food calls. For each call, we calculated the frequency ratio between the maximum and the minimum values of the fundamental frequency, and we investigated which frequency ratios occurred with higher probability. We found that, for all call types, the most frequent ratios matched perfect consonance, like an arpeggio in pop music. These music-like intervals, based on the auditory frequency resolution of chicks, cannot be miscategorized into contiguous dissonant intervals. When we analysed frequency ratio distributions at a finer-grained level, we found some dissonant ratios in the contact calls produced during distress only, thus sounding a bit jazzy. Complementing the empirical data, our computational simulations suggest that physiological constraints can only partly explain both consonances and dissonances in chicks' phonation. Our data add to the mounting evidence that the building blocks of human musical traits can be found in several species, even phylogenetically distant from us.},
  langid = {english},
  file = {/Users/jellevanderwerff/Zotero/storage/DRZ4J9T5/Maldarelli et al. - 2024 - Chicks produce consonant, sometimes jazzy, sounds.pdf}
}

@article{manriquezpBioacousticClassificationSmall2024,
  title = {Bioacoustic Classification of a Small Dataset of Mammalian Vocalisations Using Deep Learning},
  author = {Manriquez P, Rodrigo and Kotz, Sonja A. and Ravignani, Andrea and De Boer, Bart},
  year = 2024,
  month = jul,
  journal = {Bioacoustics},
  volume = {33},
  number = {4},
  pages = {354--371},
  issn = {0952-4622, 2165-0586},
  doi = {10.1080/09524622.2024.2354468},
  urldate = {2026-02-26},
  langid = {english},
  file = {/Users/jellevanderwerff/Zotero/storage/4QIKZSH3/Manriquez P et al. - 2024 - Bioacoustic classification of a small dataset of mammalian vocalisations using deep learning.pdf}
}

@inproceedings{manriquezSpikingNeuralNetwork2025,
  title = {A Spiking Neural Network for Investigation Auditory Rhythm Processing: 8th International Conference on Auditory Cortex},
  shorttitle = {A Spiking Neural Network for Investigation Auditory Rhythm Processing},
  booktitle = {8th {{International Conference}} on {{Auditory Cortex}}},
  author = {Manriquez, Rodrigo and Kotz, Sonja A. and Ravignani, Andrea and De Boer, Bart},
  year = 2025,
  month = sep,
  urldate = {2026-02-26},
  abstract = {While artificial intelligence and deep learning models have gained significant attention in neuroscience, there is still a need for more biologically realistic models to capture the dynamics of specific brain functions. Spiking Neural Networks (SNNs) may fill this gap by using the precise timing of spikes as the main mechanism for information processing, offering greater biological plausibility. In this study, we put forward  a spiking neural network framework for auditory rhythm processing, focusing on its detection and representation.Our approach involves encoding auditory signals into spike trains, using a biologically inspired subcortical model of sound processing. This model simulates peripheral auditory functions, particularly the auditory transduction that occurs at the cochlear level, by reproducing auditory nerve responses tuned to specific characteristic frequencies. For each characteristic frequency, a spike train is generated. In this way, raw acoustic waveforms are converted into a temporally precise spiking representation that preserves key temporal features of the input. The encoded spiking data is then processed using a spiking autoencoder, a neural architecture designed to learn efficient representations of the input. The autoencoder is trained to reconstruct the amplitude envelope of the acoustic signal at its output layer, effectively capturing rhythmic and amplitude modulations present in the original sound. Through our simulations, we can demonstrate that when the network is trained on isochronous rhythmic sequences, i.e. acoustic sequences where time intervals between successive events have the same duration, emergent rhythmic patterns materialize  in the latent representations learned by the spiking autoencoder. The network learns the timing of onsets and develops predictive capabilities, allowing for the anticipation of subsequent rhythmic events. This sensitivity reflects a form of temporal expectation encoded within the spike-based architecture.To further investigate the network's ability to encode rhythmic structures, we evaluate its performance with  alternative rhythmic paradigms, such as missing  beats and alternating high and low-amplitude pulses. These simulations can reveal the nature of  timing representations learned by the network, emphasising how it relies on temporal features of the input to anticipate subsequent pulses. Moreover, our findings support the hypothesis that rhythm encoding can arise from purely spike-based processing, also reinforcing the biological plausibility of SNNs in  auditory neuroscience  research.},
  langid = {english}
}

@misc{martinRooksCorvusFrugilegus2025,
  title = {Rooks (Corvus Frugilegus) Spontaneously Attempt to Vocally Entrain to Rhythmic Stimuli},
  author = {Martin, Killian and Tomasek, Ma{\"e}lan and Hivet, Agn{\`e}s and Ravignani, Andrea and Obin, Nicolas and Dufour, Val{\'e}rie},
  year = 2025,
  month = jun,
  publisher = {In Review},
  doi = {10.21203/rs.3.rs-6785900/v1},
  urldate = {2026-02-26},
  abstract = {Abstract           Musicality is the predisposition to process and produce music. In human beings, processing and producing music often involves entrainment, the ability to synchronise behaviour to external rhythms. Non-human primates generally exhibit poor entrainment skills, which may be due to their relative lack of vocal learning. Focusing on non-primate species like songbird species, is one way to investigate further the evolution of musicality. Here, we investigate spontaneous vocal entrainment in rooks, a social corvid, using non-biologically relevant stimuli. We exposed individual rooks to non natural sound stimuli and tested the effect of various tempos and metrical structures on their willingness to sing along, and on their capacity to entrain (singing along the tempo or the meter, or both). Several individuals sang while listening to the stimuli. Among them, two individuals were influenced by particular tempi and/or metrical structures: one bird produced shorter vocalisations at slower tempo and another reduced the intervals between its vocalisations upon hearing isochronous sequences with a unary metre and slow tempo. Still, the timing of the start of their vocalisations did not match accurately the timing of the beat of the stimuli. Our results suggest that rooks attempted to vocally entrain, an as-yet rare demonstration of vocal flexibility, even among open-ended vocal learners. Despite their evolutionary distance from humans, rooks, and possibly other corvids and songbirds, are interesting species for future studies on rhythmic perception, and could help shed light on the evolution of musical abilities.},
  archiveprefix = {In Review},
  copyright = {https://creativecommons.org/licenses/by/4.0/},
  langid = {english}
}

@article{martinRooksCorvusFrugilegus2026,
  title = {Rooks (Corvus Frugilegus) Can Show Spontaneous Vocal Flexibility When Exposed to Dynamically Changing Rhythmic Sounds},
  author = {Martin, K. and Tomasek, M. and Hivet, A. and Ravignani, A. and Obin, N. and Dufour, V.},
  year = 2026,
  month = jan,
  journal = {Animal Cognition},
  volume = {29},
  number = {1},
  pages = {18},
  issn = {1435-9456},
  doi = {10.1007/s10071-025-02038-w},
  urldate = {2026-02-26},
  langid = {english}
}

@article{osieckaIsochronyBarksCape2024,
  title = {Isochrony in Barks of Cape Fur Seal ( {{{\emph{Arctocephalus}}}}{\emph{ Pusillus Pusillus}} ) Pups and Adults},
  author = {Osiecka, Anna N. and Fearey, Jack and Ravignani, Andrea and Burchardt, Lara S.},
  year = 2024,
  month = mar,
  journal = {Ecology and Evolution},
  volume = {14},
  number = {3},
  pages = {e11085},
  issn = {2045-7758, 2045-7758},
  doi = {10.1002/ece3.11085},
  urldate = {2026-02-26},
  abstract = {Abstract                            Animal vocal communication often relies on call sequences. The temporal patterns of such sequences can be adjusted to other callers, follow complex rhythmic structures or exhibit a metronome-like pattern (i.e., isochronous). How regular are the temporal patterns in animal signals, and what influences their precision? If present, are rhythms already there early in ontogeny? Here, we describe an exploratory study of Cape fur seal (               Arctocephalus pusillus pusillus               ) barks---a vocalisation type produced across many pinniped species in rhythmic, percussive bouts. This study is the first quantitative description of barking in Cape fur seal pups. We analysed the rhythmic structures of spontaneous barking bouts of pups and adult females from the breeding colony in Cape Cross, Namibia. Barks of adult females exhibited isochrony, that is they were produced at fairly regular points in time. Instead, intervals between pup barks were more variable, that is skipping a bark in the isochronous series occasionally. In both age classes, beat precision, that is how well the barks followed a perfect template, was worse when barking at higher rates. Differences could be explained by physiological factors, such as respiration or arousal. Whether, and how, isochrony develops in this species remains an open question. This study provides evidence towards a rhythmic production of barks in Cape fur seal pups and lays the groundwork for future studies to investigate the development of rhythm using multidimensional metrics.},
  langid = {english}
}

@article{ozakiGloballySongsInstrumental2024,
  title = {Globally, Songs and Instrumental Melodies Are Slower and Higher and Use More Stable Pitches than Speech: A Registered Report},
  shorttitle = {Globally, Songs and Instrumental Melodies Are Slower and Higher and Use More Stable Pitches than Speech},
  author = {Ozaki, Yuto and Tierney, Adam and Pfordresher, Peter Q. and McBride, John M. and Benetos, Emmanouil and Proutskova, Polina and Chiba, Gakuto and Liu, Fang and Jacoby, Nori and Purdy, Suzanne C. and Opondo, Patricia and Fitch, W. Tecumseh and Hegde, Shantala and Rocamora, Mart{\'i}n and Thorne, Rob and Nweke, Florence and Sadaphal, Dhwani P. and Sadaphal, Parimal M. and Hadavi, Shafagh and Fujii, Shinya and Choo, Sangbuem and Naruse, Marin and Ehara, Utae and Sy, Latyr and Parselelo, Mark Lenini and {Anglada-Tort}, Manuel and Hansen, Niels Chr. and Haiduk, Felix and F{\ae}r{\o}vik, Ulvhild and Magalh{\~a}es, Violeta and Krzy{\.z}anowski, Wojciech and Shcherbakova, Olena and Hereld, Diana and Barbosa, Brenda Suyanne and Varella, Marco Antonio Correa and Van Tongeren, Mark and Dessiatnitchenko, Polina and Zar, Su Zar and El Kahla, Iyadh and Muslu, Olcay and Troy, Jakelin and Lomsadze, Teona and Kurdova, Dilyana and Tsope, Cristiano and Fredriksson, Daniel and Arabadjiev, Aleksandar and Sarbah, Jehoshaphat Philip and Arhine, Adwoa and Meachair, Tadhg {\'O} and {Silva-Zurita}, Javier and {Soto-Silva}, Ignacio and Millalonco, Neddiel Elcie Mu{\~n}oz and Ambrazevi{\v c}ius, Rytis and Loui, Psyche and Ravignani, Andrea and Jadoul, Yannick and {Larrouy-Maestri}, Pauline and Bruder, Camila and Teyxokawa, Tutushamum Puri and Kuikuro, Urise and Natsitsabui, Rogerdison and Sagarzazu, Nerea Bello and Raviv, Limor and Zeng, Minyu and Varnosfaderani, Shahaboddin Dabaghi and {G{\'o}mez-Ca{\~n}{\'o}n}, Juan Sebasti{\'a}n and Kolff, Kayla and Der Nederlanden, Christina Vanden Bosch and Chhatwal, Meyha and David, Ryan Mark and Setiawan, I. Putu Gede and Lekakul, Great and Borsan, Vanessa Nina and Nguqu, Nozuko and Savage, Patrick E.},
  year = 2024,
  month = may,
  journal = {Science Advances},
  volume = {10},
  number = {20},
  pages = {eadm9797},
  issn = {2375-2548},
  doi = {10.1126/sciadv.adm9797},
  urldate = {2026-02-26},
  abstract = {Both music and language are found in all known human societies, yet no studies have compared similarities and differences between song, speech, and instrumental music on a global scale. In this Registered Report, we analyzed two global datasets: (i) 300 annotated audio recordings representing matched sets of traditional songs, recited lyrics, conversational speech, and instrumental melodies from our 75 coauthors speaking 55 languages; and (ii) 418 previously published adult-directed song and speech recordings from 209 individuals speaking 16 languages. Of our six preregistered predictions, five were strongly supported: Relative to speech, songs use (i) higher pitch, (ii) slower temporal rate, and (iii) more stable pitches, while both songs and speech used similar (iv) pitch interval size and (v) timbral brightness. Exploratory analyses suggest that features vary along a ``musi-linguistic'' continuum when including instrumental melodies and recited lyrics. Our study provides strong empirical evidence of cross-cultural regularities in music and speech.           ,              Global collaboration by 75 researchers finds acoustic relationships between speech, song, and instrumental music across cultures.},
  langid = {english},
  file = {/Users/jellevanderwerff/Zotero/storage/UNWFLSIB/Ozaki et al. - 2024 - Globally, songs and instrumental melodies are slower and higher and use more stable pitches than spe.pdf}
}

@article{parsonsSaccadicTemporalRecalibration2018,
  title = {Saccadic Temporal Recalibration Alters Action and Perception},
  author = {Parsons, Brent and Giomo, Dunia and Bueti, Domenica},
  year = 2018,
  month = sep,
  journal = {Journal of Vision},
  volume = {18},
  number = {10},
  pages = {1003},
  publisher = {{The Association for Research in Vision and Ophthalmology}},
  issn = {1534-7362},
  doi = {10.1167/18.10.1003},
  urldate = {2026-02-26},
  copyright = {http://creativecommons.org/licenses/by-nc-nd/4.0/},
  langid = {english},
  file = {/Users/jellevanderwerff/Zotero/storage/VE4UG28S/Parsons et al. - 2018 - Saccadic temporal recalibration alters action and perception.html}
}

@article{raimondiIsochronyRhythmicInteraction2023,
  title = {Isochrony and Rhythmic Interaction in Ape Duetting},
  author = {Raimondi, Teresa and Di Panfilo, Giovanni and Pasquali, Matteo and Zarantonello, Martina and Favaro, Livio and Savini, Tommaso and Gamba, Marco and Ravignani, Andrea},
  year = 2023,
  month = jan,
  journal = {Proceedings of the Royal Society B: Biological Sciences},
  volume = {290},
  number = {1990},
  pages = {20222244},
  issn = {0962-8452, 1471-2954},
  doi = {10.1098/rspb.2022.2244},
  urldate = {2026-02-26},
  abstract = {How did rhythm originate in humans, and other species? One cross-cultural universal, frequently found in human music, is isochrony: when note onsets repeat regularly like the ticking of a clock. Another universal consists in synchrony (e.g. when individuals coordinate their notes so that they are sung at the same time). An approach to biomusicology focuses on similarities and differences across species, trying to build phylogenies of musical traits. Here we test for the presence of, and a link between, isochrony and synchrony in a non-human animal. We focus on the songs of one of the few singing primates, the lar gibbon (               Hylobates lar               ), extracting temporal features from their solo songs and duets. We show that another ape exhibits one rhythmic feature at the core of human musicality: isochrony. We show that an enhanced call rate overall boosts isochrony, suggesting that respiratory physiological constraints play a role in determining the song's rhythmic structure. However, call rate alone cannot explain the flexible isochrony we witness. Isochrony is plastic and modulated depending on the context of emission: gibbons are more isochronous when duetting than singing solo. We present evidence for rhythmic interaction: we find statistical causality between one individual's note onsets and the co-singer's onsets, and a higher than chance degree of synchrony in the duets. Finally, we find a sex-specific trade-off between individual isochrony and synchrony. Gibbon's plasticity for isochrony and rhythmic overlap may suggest a potential shared selective pressure for interactive vocal displays in singing primates. This pressure may have convergently shaped human and gibbon musicality while acting on a common neural primate substrate. Beyond humans, singing primates are promising models to understand how music and, specifically, a sense of rhythm originated in the primate phylogeny.},
  langid = {english},
  file = {/Users/jellevanderwerff/Zotero/storage/EDYVZLVA/Raimondi et al. - 2023 - Isochrony and rhythmic interaction in ape duetting.pdf;/Users/jellevanderwerff/Zotero/storage/F5I59A2L/rspb.2022.html}
}

@article{raimondiLearntFormantModulation2026,
  title = {Learnt Formant Modulation via Upper Vocal Tract Movements in a Marine Mammal},
  author = {Raimondi, Teresa and D'Orazio, Francesca and Di Martino, Denise and Witt, Melina and Grenga, Flavia and Cook, Peter and Favaro, Livio and Pilenga, Cristina and Ravignani, Andrea},
  year = 2026,
  month = jan,
  journal = {Discover Animals},
  volume = {3},
  number = {1},
  pages = {2--30},
  issn = {3004-894X},
  doi = {10.1007/s44338-025-00145-z},
  urldate = {2026-02-26},
  langid = {english},
  file = {/Users/jellevanderwerff/Zotero/storage/ZDJNSS2Z/Raimondi et al. - 2026 - Learnt formant modulation via upper vocal tract movements in a marine mammal.pdf}
}

@article{raimondiNeonatalAuditoryInput2026,
  included = {true},
  title = {Neonatal Auditory Input Affects Vocal Development in Harbour Seals},
  author = {Raimondi, Teresa and Haas, Caroline E. and De Reus, Koen and {Mendez-Arostegui}, Margarita and Jadoul, Yannick and Ravignani, Andrea},
  year = 2026,
  month = feb,
  journal = {Philosophical Transactions B},
  volume = {381},
  number = {1943},
  pages = {20240369},
  publisher = {The Royal Society},
  issn = {0962-8436, 1471-2970},
  doi = {10.1098/rstb.2024.0369},
  urldate = {2026-02-26},
  abstract = {Abstract             Vocal individuality has important biological functions in mammals: at crucial stages of development, it ensures feeding and is a prerequisite for auditory-based mother--pup recognition. Is vocal individuality only shaped by maturation or also by the degree of conspecific acoustic input? Here, we test how the neonatal auditory environment shapes development and individualization of calls in harbour seal pups (Phoca vitulina). To simulate low- versus high-conspecific acoustic density, 18 pups heard playbacks of calls from either 2 or 30 conspecifics. We recorded calls before and after playback exposure and extracted 12 acoustic parameters. Supervised machine learning and discriminant function analyses showed greater individual distinctiveness in both groups after playback, indicating a developmental trend toward individualization. Notably, pups exposed to less-variable input showed higher individuality. Euclidean distances on call parameters showed that both groups diverged from the playback signals. Distances on within-pup and between-pups housed together revealed opposite trajectories in the two groups: after the exposure, less-variable auditory input determined steadier individual calls, while more-variable auditory input scattered calls across the acoustic space. Altogether, our findings indicate that auditory input modulates vocal development in pups, making harbour seals a promising model for unravelling how neonatal environment affects vocal plasticity in a non-human mammal.             This article is part of the theme issue `Mechanisms of learning from social interaction'.},
  copyright = {http://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  file = {/Users/jellevanderwerff/Zotero/storage/PYAFXYNJ/Raimondi et al. - 2026 - Neonatal auditory input affects vocal development in harbour seals.pdf;/Users/jellevanderwerff/Zotero/storage/BV3KG275/rstb.2024.html}
}

@article{raimondiRhythmWombBroad2025,
  title = {Rhythm in the Womb: A Broad Comparative Approach to Auditory and Motor Entrainment},
  shorttitle = {Rhythm in the Womb},
  author = {Raimondi, Teresa and Ravignani, Andrea},
  year = 2025,
  journal = {Current Anthropology},
  publisher = {Chicago},
  urldate = {2026-02-26},
  abstract = {reserved},
  langid = {english}
}

@article{ravignaniVisualizingInterpretingRhythmic2017,
  title = {Visualizing and Interpreting Rhythmic Patterns Using Phase Space Plots},
  author = {Ravignani, Andrea},
  year = 2017,
  month = jun,
  journal = {Music Perception},
  volume = {34},
  number = {5},
  pages = {557--568},
  publisher = {University of California Press},
  issn = {0730-7829, 1533-8312},
  doi = {10.1525/mp.2017.34.5.557},
  urldate = {2026-02-26},
  abstract = {Structure in musical rhythm can be measured using a number of analytical techniques. While some techniques---like circular statistics or grammar induction---rely on strong top-down assumptions, assumption-free techniques can only provide limited insights on higher-order rhythmic structure. I suggest that research in music perception and performance can benefit from systematically adopting phase space plots, a visualization technique originally developed in mathematical physics that overcomes the aforementioned limitations. By jointly plotting adjacent interonset intervals (IOI), the motivic rhythmic structure of musical phrases, if present, is visualized geometrically without making any a priori assumptions concerning isochrony, beat induction, or metrical hierarchies. I provide visual examples and describe how particular features of rhythmic patterns correspond to geometrical shapes in phase space plots. I argue that research on music perception and systematic musicology stands to benefit from this descriptive tool, particularly in comparative analyses of rhythm production. Phase space plots can be employed as an initial assumption-free diagnostic to find higher order structures (i.e., beyond distributional regularities) before proceeding to more specific, theory-driven analyses.},
  langid = {english},
  file = {/Users/jellevanderwerff/Zotero/storage/7LGBNTYS/Ravignani - 2017 - Visualizing and Interpreting Rhythmic Patterns Usi.pdf}
}

@article{rossiTestingRhythmicAbilities2024,
  title = {Testing Rhythmic Abilities in Developmental Dyslexia},
  author = {Rossi, Marina and Smit, Eline A. and {van der Werff}, Jelle and Ravignani, Andrea and Rathcke, Tamara},
  year = 2024,
  month = dec,
  journal = {Music Perception: An Interdisciplinary Journal},
  volume = {42},
  number = {2},
  pages = {135--148},
  publisher = {University of California Press},
  issn = {0730-7829, 1533-8312},
  doi = {10.1525/mp.2024.42.2.135},
  urldate = {2026-02-26},
  abstract = {Rhythm processing deficits in developmental dyslexia (DD) span across different rhythmic subcomponents and are difficult to capture using one experimental paradigm. How are dyslexic deficits related to motor periodicity, i.e., the execution of repetitive actions while internally generating rhythm? The present experiment investigated rhythm production in DD by means of unprompted tapping paradigm, testing the hypothesis that the ability to internally generate rhythmic patterns may be impaired. The tasks involved tapping of isochronous sequences at a comfortable and a fast tempo and tapping of a free rhythm. Forty adolescents diagnosed with DD (with or without comorbid dyscalculia) participated, along with thirty typically developing control participants. A background questionnaire gathered information about participants' prior music training. The data show that both dyslexic groups tapped faster than the typically developing participants at the comfortable tempo. We found no statistical differences between groups in fast isochronous tapping or in the free rhythm production tasks, irrespective of music training or the presence of dyscalculia. All participants favored regular rhythms when tapping a free rhythm, with a notable preference for isochrony. These results have theoretical and clinical implications for rhythm deficit hypotheses of DD.},
  langid = {english},
  file = {/Users/jellevanderwerff/Zotero/storage/W6Y2R44X/Rossi et al. - 2024 - Testing rhythmic abilities in developmental dyslexia.pdf}
}

@misc{savageDoesSynchronisedSinging2025,
  title = {Does Synchronised Singing Enhance Social Bonding More than Speaking Does? {{A}} Global Experimental Stage 1 Registered Report},
  shorttitle = {Does Synchronised Singing Enhance Social Bonding More than Speaking Does?},
  author = {Savage, Patrick E. and {Ampiah-Bonney}, Adwoa and Arabadjiev, Aleksandar and Arhine, Adwoa and Ariza, Juan F. and Bamford, Joshua Silberstein and Barbosa, Brenda Suyanne and Beck, Ann-Kathrin and Belyk, Michel and Benetos, Emmanouil and Bulbulia, Joseph and Cabildo, Anne and Calhoun, Sasha and Chiba, Gakuto and Duran, Stephen Ithel and F{\ae}r{\o}vik, Ulvhild and Fitch, Tecumseh and Fujii, Shinya and Gabriel, Shira and Haiduk, Felix and Hansen, Niels Chr. and Hegde, Shantala and Honbolyg{\'o}, Ferenc and Huang, Jiawen and Jacoby, Nori and Jadoul, Yannick and Jia, Zixuan and Jung, Taeyun and Kert{\'e}sz, Csaba and Khasanah, Uswatun and Kim, Inkuk and Kitayama, Yoichi and Krzy{\.z}anowski, Wojciech and Kuikuro, Urise and Kurdova, Dilyana and {Larrouy-Maestri}, Pauline and Leong{\'o}mez, Juan David and Liu, Fang and Lomsadze, Teona and Loui, Psyche and Ma, Yiqing and Mcbride, John and Moya, Dayna and Natsitsabui, Rogerdison and Novembre, Giacomo and Nweke, Florence Ewomazino and Opondo, Patricia and Ozaki, Yuto and Parkinson, Hineatua and Parselelo, Mark Lenini and Pavlovich, Danya Vivianne and Pfordresher, Peter and Pisanski, Katarzyna and Podlipniak, Piotr and Popescu, Tudor and Proutskova, Polina and Purdy, Suzanne and Ravignani, Andrea and Raviv, Limor and Sadaphal, Dhwani P. and Shakya, Swayambhu Ratna and Shilton, Dor and {Silva-Zurita}, Javier and {Soto-Silva}, Ignacio and Tarr, Bronwyn and Tierney, Adam and Tiratanti, Prapatsorn and Trainor, Laurel and Der Nederlanden, Christina and Varella, Marco Antonio Correa and Varnosfaderani, Shahaboddin Dabaghi and Youngblood, Mason and Zariquiey, Roberto},
  year = 2025,
  month = apr,
  publisher = {PsyArXiv},
  doi = {10.31234/osf.io/pv3m9_v3},
  urldate = {2026-02-26},
  abstract = {The evolution of music, speech, and sociality have been debated since before Darwin. The social bonding hypothesis proposes that these phenomena may be interlinked: musicality may have facilitated the evolution of social bonding beyond the possibilities of spoken language. Although dozens of experimental studies have argued that synchronised rhythms can promote bonding, methodological issues including publication bias, sample bias, experimenter effects, and appropriateness of experimental controls make it unclear whether synchronous singing reliably and generally enhances bonding relative to speaking. Here, we propose a Registered Report to overcome these issues through a global experiment in diverse languages aiming to collect data from 1800 participants across 60 sites. The social bonding hypothesis predicts that bonding will increase more after synchronous singing than after spoken (sequential) conversation or (simultaneous) recitation, while alternative hypotheses predict that song will not increase bonding relative to speech. Regardless of outcome, these results will provide an unprecedented understanding of cross-cultural relationships between music, speech, and sociality.},
  copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
  langid = {english}
}

@article{savageProgrammaticStage12025,
  title = {A Programmatic Stage 1 Registered Report of Global Song-Speech Relationships Replicating and Extending Ozaki et al.(2024) and Savage et al. 2},
  author = {Savage, Patrick E. and Jia, Zixuan},
  year = 2025,
  journal = {databases},
  volume = {1},
  pages = {25--27},
  urldate = {2026-02-26},
  langid = {english},
  file = {/Users/jellevanderwerff/Zotero/storage/SHFVNUEW/Savage e Jia - 2025 - A programmatic stage 1 registered report of global song-speech relationships replicating and extendi.pdf}
}

@incollection{valenteBioacousticsRhythm2025,
  title = {Bioacoustics and Rhythm},
  booktitle = {The Oxford Handbook of Approaches to Language Evolution},
  author = {Valente, Daria and Ravignani, Andrea},
  editor = {Raviv, Limor and Boeckx, Cedric},
  year = 2025,
  month = may,
  edition = {1},
  pages = {539--552},
  publisher = {Oxford University Press},
  doi = {10.1093/oxfordhb/9780192886491.013.27},
  urldate = {2026-02-26},
  abstract = {Abstract             Bioacoustics is an interdisciplinary science; it concerns aspects of communication through sound in animals, including humans. Within language evolution research, bioacoustics is particularly relevant to address questions about the origins and evolution of speech. Areas of bioacoustics research include the perception and production of acoustic signals, their transmission in the environment, and the neural and anatomical correlates that determine and influence communication. Here, we review the tools needed to conduct bioacoustics research, from initial methodological choices to instrument choice, based on critical features needed for data collection in the field. We discuss key methodological choices in sound recording and processing raw data from a data collection campaign. We provide recommendations for the recording and use of acoustic signals. We discuss analysis techniques, focusing exclusively on rhythm in animal vocalizations. We conclude by stressing the potential for multidisciplinary collaborations, and highlighting key areas where these collaborations could happen.},
  isbn = {978-0-19-288649-1 978-0-19-198159-3},
  langid = {english},
  file = {/Users/jellevanderwerff/Zotero/storage/LPYB34J6/Valente e Ravignani - 2025 - Bioacoustics and rhythm.pdf}
}

@article{vanderwerffHumansCanFind2025,
  title = {Humans Can Find Rhythm in Randomly Timed Sounds},
  author = {{van der Werff}, Jelle and Tufarelli, Tommaso and Verga, Laura and Ravignani, Andrea},
  year = 2025,
  month = aug,
  journal = {Royal Society Open Science},
  volume = {12},
  number = {8},
  pages = {250453},
  publisher = {Royal Society},
  issn = {2054-5703},
  doi = {10.1098/rsos.250453},
  urldate = {2026-02-26},
  abstract = {Humans are keen pattern-seekers and take advantage of regularities present in their environment. In the temporal domain, we may call these patterns rhythms, but what is rhythm? Definitions vary, but all presuppose a categorical distinction between rhythm and randomness. Here, we challenge this view and show that two types of random sound sequences---classically considered arrhythmic by experimenters---differ in the amount of regularity humans reconstruct from them. When asked to synchronize to randomly timed sounds, participants leverage statistics to estimate the underlying tempo of the sequence, similar to linear statistical estimators. Theoretically, our results challenge current definitions of rhythm by showing that rhythmicity and randomness are instances of a continuum. Methodologically, our data and mathematical model show that a common method for creating random timing, namely the jittering of event onsets, introduces an undesirable regularity that humans readily exploit. New experiments should aim to maximize temporal randomness, and past experiments' outcomes require reconsideration.},
  langid = {english},
  keywords = {rhythm,temporal randomness,timing},
  file = {/Users/jellevanderwerff/Zotero/storage/9HS3UDBW/van der Werff et al. - 2025 - Humans can find rhythm in randomly timed sounds.pdf}
}

@article{vanderwerffThebeatPythonPackage2024,
  title = {Thebeat: A Python Package for Working with Rhythms and Other Temporal Sequences},
  shorttitle = {Thebeat},
  author = {{van der Werff}, Jelle and Ravignani, Andrea and Jadoul, Yannick},
  year = 2024,
  month = feb,
  journal = {Behavior Research Methods},
  volume = {56},
  number = {4},
  pages = {3725--3736},
  issn = {1554-3528},
  doi = {10.3758/s13428-023-02334-8},
  urldate = {2026-02-26},
  abstract = {Abstract                            thebeat               is a Python package for working with temporal sequences and rhythms in the behavioral and cognitive sciences, as well as in bioacoustics. It provides functionality for creating experimental stimuli, and for visualizing and analyzing temporal data. Sequences, sounds, and experimental trials can be generated using single lines of code.               thebeat               contains functions for calculating common rhythmic measures, such as interval ratios, and for producing plots, such as circular histograms.               thebeat               saves researchers time when creating experiments, and provides the first steps in collecting widely accepted methods for use in timing research.               thebeat               is an open-source, on-going, and collaborative project, and can be extended for use in specialized subfields.               thebeat               integrates easily with the existing Python ecosystem, allowing one to combine our tested code with custom-made scripts. The package was specifically designed to be useful for both skilled and novice programmers.               thebeat               provides a foundation for working with temporal sequences onto which additional functionality can be built. This combination of specificity and plasticity should facilitate research in multiple research contexts and fields of study.},
  copyright = {All rights reserved},
  langid = {english},
  keywords = {Acoustics,Bioacoustics,Music,Python,Rhythm,Timing},
  file = {/Users/jellevanderwerff/Zotero/storage/SQ3K53A8/van der Werff et al. - 2024 - thebeat A Python package for working with rhythms and other temporal sequences.pdf;/Users/jellevanderwerff/Zotero/storage/UPS8QWGL/van der Werff et al. - 2024 - thebeat A Python package for working with rhythms.pdf}
}

@article{zaniniEffectsAnimacyProcessing2020,
  title = {Effects of Animacy on the Processing of Morphological Number: A Cognitive Inheritance?},
  shorttitle = {Effects of Animacy on the Processing of Morphological Number},
  author = {Zanini, Chiara and Rugani, Rosa and Giomo, Dunia and Peressotti, Francesca and Franzon, Francesca},
  year = 2020,
  month = mar,
  journal = {Word Structure},
  volume = {13},
  number = {1},
  pages = {22--44},
  issn = {1750-1245, 1755-2036},
  doi = {10.3366/word.2020.0158},
  urldate = {2026-02-26},
  abstract = {Language encodes into morphology part of the information present in the referential world. Some features are marked in the great majority of languages, such as the numerosity of the referents that is encoded in morphological Number. Other features do not surface as frequently in morphological markings, yet they are pervasive in natural languages. This is the case of animacy, that can ground Gender systems as well as constrain the surfacing of Number. The diffusion of numerosity and animacy could mirror their biological salience at the extra-linguistic cognitive level. Human extra-linguistic numerical abilities are phylogenetically ancient and are observed in non-human animal species, especially when counting salient animate entities such as social companions. Does the saliency of animacy influence the morphological encoding of Number in language processing?             We designed an experiment to test the encoding of morphological Number in language processing in relation to animacy. In Italian, Gender and Number are mandatorily expressed in a fusional morpheme. In some nouns denoting animate referents, Gender encodes the sex of referents and is semantically interpretable. In some other animate nouns and in inanimate nouns, Gender is uninterpretable at the semantic level. We found that it is easier to inflect for Number nouns when the inflectional morpheme is interpretable with respect to a semantic feature related to animacy. We discuss the possibility that the primacy of animacy in counting is mirrored in morphological processing and that morphology is designed to easily express information that is salient from a cognitive point of view.},
  copyright = {https://www.euppublishing.com/customer-services/librarians/text-and-data-mining-tdm},
  langid = {english},
  file = {/Users/jellevanderwerff/Zotero/storage/L86R7CZ8/Zanini et al. - 2020 - Effects of animacy on the processing of morphological number a cognitive inheritance.pdf}
}
